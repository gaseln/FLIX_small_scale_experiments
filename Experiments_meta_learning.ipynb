{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workers import MasterNode\n",
    "from models import LinReg, LogReg, LogRegNoncvx, NN_1d_regression\n",
    "from utils import read_run, get_alg, create_plot_dir, PLOT_PATH\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from prep_data import number_of_features\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from numpy.random import default_rng\n",
    "from numpy import linalg as la\n",
    "from prep_data import DATASET_PATH\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fast')\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "# mpl.rcParams['mathtext.fontset'] = 'dejavusans'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['lines.linewidth'] = 2.0\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
    "mpl.rcParams['xtick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['ytick.labelsize'] = 'x-large'\n",
    "mpl.rcParams['axes.labelsize'] = 'xx-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['x', '.', '+', '1', 'p','*', 'D' , '.',  's']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1. Can weak models collaboratively train one good global model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium size dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 50\n",
    "number_of_points_per_task = 30\n",
    "dataset_name = 'artificial_sine_medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "for i in range(number_of_tasks):\n",
    "    a = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "    a_array.append(a)\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    b_array.append(b)\n",
    "    x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "    y_train = a * np.sin(x_train + b)\n",
    "    X_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = x_train.copy()\n",
    "    y_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = y_train.squeeze(1).copy()\n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(5, number_of_tasks)):\n",
    "    inds = range(number_of_points_per_task * i, number_of_points_per_task * (i + 1))\n",
    "    plt.scatter(X_sine[inds], y_sine[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=0.1)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(10):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].w_opt_global = np.zeros(models[0].d)\n",
    "models[0].change_alpha(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    model = models[i]\n",
    "    min_L = 1e-6\n",
    "    max_L = 0.1\n",
    "    max_it = 100000\n",
    "    tol = 0.1\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                  break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'models' : models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_medium', 'wb') as file:\n",
    "    pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on existing clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(5, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(models[i].workers[0].alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(5):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on a new client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "n_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_cn = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "b_cn = rng.random() * 2 * np.pi\n",
    "x_train_cn = -5.0 + rng.random((n_train, 1)) * 10.0\n",
    "y_train_cn = a_cn * np.sin(x_train_cn + b_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train_cn, y_train_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_node = NN_1d_regression(id_node=1000, alpha=0.5, x_train=x_train_cn, y_train=y_train_cn, regularization=None, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_node.set_weights(control_node.w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = control_node.model(torch.from_numpy(x_train_cn).float()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train_cn, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cn = -5.0 + rng.random((n_test, 1)) * 10.0\n",
    "y_test_cn = a_cn * np.sin(x_test_cn + b_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test_cn, y_test_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_array = np.empty(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    control_node.alpha = 0.1 * i\n",
    "    control_node.set_weights(control_node.compute_local(models[i].w_opt_global))\n",
    "    y_prediction_cn = control_node.model(torch.from_numpy(x_test_cn).float()).detach().numpy()\n",
    "    mse_array[i] = np.mean((y_prediction_cn - y_test_cn) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, at least in the checked set-ups weak models do not give a good global model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2. How much do few gradient steps help the mixed model (if it helps at all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + 'models_extended', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].n_workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision to which each worker is trained to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(models[0].n_workers):\n",
    "    curr_worker = models[0].workers[i]\n",
    "    print(i, curr_worker.fun_value(curr_worker.w_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision to which each global model is trained to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of workers is large. The higher alpha is, the harder is to train the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].alpha = np.zeros(models[0].n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_gradient_steps(test_node, trained_global_model, num_grad_steps, stepsize):\n",
    "    assert np.std(trained_global_model.alpha) < 1e-5\n",
    "    test_node.alpha = trained_global_model.alpha[0]\n",
    "    w = copy.deepcopy(trained_global_model.w_opt_global)\n",
    "    for step in range(num_grad_steps):\n",
    "        grad = test_node.grad_shift(test_node.x_train, test_node.y_train, w)\n",
    "        w -= stepsize * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points = 50\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "b = rng.random() * 2 * np.pi\n",
    "x_train = -5.0 + rng.random((number_of_points, 1)) * 10.0\n",
    "y_train = a * np.sin(x_train + b)\n",
    "test_node = NN_1d_regression(id_node=1000, alpha=0.1, x_train=x_train, y_train=y_train, regularization=None, tolerance=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = few_gradient_steps(test_node, models[1], 5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_experiments = 1\n",
    "number_of_train_points = 50\n",
    "number_of_test_points = 1000\n",
    "grad_steps = [0, 5, 10, 15]\n",
    "rng = default_rng()\n",
    "mse_table = np.zeros(shape=(len(models), len(grad_steps)))\n",
    "for ind in range(number_of_experiments):\n",
    "    a = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    x_train = -5.0 + rng.random((number_of_train_points, 1)) * 10.0\n",
    "    y_train = a * np.sin(x_train + b)\n",
    "    x_test = -5.0 + rng.random((number_of_train_points, 1)) * 10.0\n",
    "    y_test = a * np.sin(x_test + b)\n",
    "    test_node = NN_1d_regression(id_node=1000, alpha=0.1, x_train=x_train, y_train=y_train, regularization=None, tolerance=1e-2)\n",
    "    ind_1 = 0\n",
    "    for model in models:\n",
    "        ind_2 = 0\n",
    "        for num_grad_steps in grad_steps:\n",
    "            w = few_gradient_steps(test_node, model, num_grad_steps, 1e-3)\n",
    "            test_node.set_weights(test_node.compute_local(w))\n",
    "            y_predicted = test_node.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "            mse_table[ind_1][ind_2] += np.mean((y_predicted - y_test) ** 2) / number_of_experiments\n",
    "            ind_2 += 1\n",
    "        ind_1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3. Constant a, large number of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 1000\n",
    "number_of_points_per_task = 20\n",
    "dataset_name = 'artificial_sine_a_constant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "b_array = []\n",
    "for i in range(number_of_tasks):\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    b_array.append(b)\n",
    "    x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "    y_train = np.sin(x_train + b)\n",
    "    X_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = x_train.copy()\n",
    "    y_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = y_train.squeeze(1).copy()\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'b_constant.npy', b_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 1\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=0.1)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training global models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.9, 1.01, 0.01, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'models' : models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + 'a_constant_1000', 'wb') as file:\n",
    "    pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models[0].change_alpha(0.0)\n",
    "# models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 100000\n",
    "    tol = 0.1\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global) if i != 0 else np.zeros(models[0].d)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer_of_test_tasks = 25\n",
    "for i in range(numer_of_test_tasks):\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "    y_train = np.sin(x_train + b)\n",
    "    x_test =  -5.0 + rng.random((1000, 1)) * 10.0\n",
    "    y_test = np.sin(x_test + b)\n",
    "    tolerance = 0.1\n",
    "    test_node = NN_1d_regression(id_node=1000, alpha=0.1, x_train=x_train, y_train=y_train, regularization=None, tolerance=tolerance)\n",
    "    test_node.set_weights(test_node.w_opt)\n",
    "    y_predicted = test_node.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "    print('Alpha = 0   {}'.format(np.mean((y_predicted - y_test) ** 2)))\n",
    "    \n",
    "    test_node.set_weights(test_node.compute_local(models[1].w_opt_global))\n",
    "    y_predicted = test_node.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "    print('Alpha = 0.1 {}'.format(np.mean((y_predicted - y_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4. Basic sine experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 100\n",
    "number_of_points_per_task = 50\n",
    "dataset_name = 'artificial_sine_50_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "for i in range(number_of_tasks):\n",
    "    a = 0.1 + rng.random() * (5.0 - 0.1)\n",
    "    a_array.append(a)\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    b_array.append(b)\n",
    "    x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "    y_train = a * np.sin(x_train + b)\n",
    "    X_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = x_train.copy()\n",
    "    y_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = y_train.squeeze(1).copy()\n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)\n",
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "np.save(DATASET_PATH + 'a_50_100.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b_50_100.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + 'model_initial_50_100', 'wb') as file:\n",
    "    model_init_dict = {'model' : model}\n",
    "    pickle.load(model_init_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 100000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, '50_100')\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, '50_100')\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(models, '50_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '50_100', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_array = np.load(DATASET_PATH +'a_50_100.npy')\n",
    "# b_array = np.load(DATASET_PATH + 'b_50_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymax=mse_alpha[argmin])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(PLOT_PATH + '/50_100_MSE_over_alphas.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic sine experiment with validation criterion stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 100\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 10\n",
    "dataset_name = 'artificial_sine_50_100'\n",
    "validation_dataset_name = 'artificial_sine_10_100_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))\n",
    "rng = default_rng()\n",
    "a_array = np.load(DATASET_PATH + 'a_50_100.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b_50_100.npy')\n",
    "for i in range(number_of_tasks):\n",
    "    x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "    y_val = a_array[i] * np.sin(x_val + b_array[i])\n",
    "    X_sine_val[number_of_points_per_task_for_validation * i : number_of_points_per_task_for_validation * (i + 1)] = x_val.copy()\n",
    "    y_sine_val[number_of_points_per_task_for_validation * i : number_of_points_per_task_for_validation * (i + 1)] = y_val.squeeze(1).copy()\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + 'model_initial_50_100_validated_10', 'wb') as file:\n",
    "    model_init_dict = {'model' : model}\n",
    "    pickle.load(model_init_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, '50_100_validated')\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, '50_100_validated')\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(models, '50_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '50_100_validated', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_array = np.load(DATASET_PATH +'a_50_100.npy')\n",
    "# b_array = np.load(DATASET_PATH + 'b_50_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a_50_100.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b_50_100.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymax=mse_alpha[argmin])\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_100_MSE_over_alphas_validated_PLM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6. Weak models revisited with validation stop criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 200\n",
    "number_of_points_per_task = 20\n",
    "number_of_points_per_task_for_validation = 10\n",
    "dataset_name = 'artificial_sine_medium'\n",
    "validation_dataset_name = 'artificial_sine_medium_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "for i in range(number_of_tasks):\n",
    "    a = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "    a_array.append(a)\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    b_array.append(b)\n",
    "    x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "    x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "    y_train = a * np.sin(x_train + b)\n",
    "    y_val = a * np.sin(x_val + b)\n",
    "    X_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = x_train.copy()\n",
    "    X_sine_val[number_of_points_per_task_for_validation * i : number_of_points_per_task_for_validation * (i + 1)] = x_val.copy()    \n",
    "    y_sine[number_of_points_per_task * i : number_of_points_per_task * (i + 1)] = y_train.squeeze(1).copy()\n",
    "    y_sine_val[number_of_points_per_task_for_validation * i : number_of_points_per_task_for_validation * (i + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(5, number_of_tasks)):\n",
    "    inds = range(number_of_points_per_task * i, number_of_points_per_task * (i + 1))\n",
    "    plt.scatter(X_sine[inds], y_sine[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_medium_validated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '20_200_medium_with_validation'\n",
    "for i in range(9, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '/20_200_medium_with_validation', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=mse_alpha[argmin])\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/20_200_medium_with_validation.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on existing clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(5, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(models[i].workers[0].alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(5):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on a new client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "n_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_cn = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "b_cn = rng.random() * 2 * np.pi\n",
    "x_train_cn = -5.0 + rng.random((n_train, 1)) * 10.0\n",
    "y_train_cn = a_cn * np.sin(x_train_cn + b_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train_cn, y_train_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_node = NN_1d_regression(id_node=1000, alpha=0.5, x_train=x_train_cn, y_train=y_train_cn, regularization=None, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_node.set_weights(control_node.w_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = control_node.model(torch.from_numpy(x_train_cn).float()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train_cn, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cn = -5.0 + rng.random((n_test, 1)) * 10.0\n",
    "y_test_cn = a_cn * np.sin(x_test_cn + b_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test_cn, y_test_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_array = np.empty(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    control_node.alpha = 0.1 * i\n",
    "    control_node.set_weights(control_node.compute_local(models[i].w_opt_global))\n",
    "    y_prediction_cn = control_node.model(torch.from_numpy(x_test_cn).float()).detach().numpy()\n",
    "    mse_array[i] = np.mean((y_prediction_cn - y_test_cn) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 7. Two distribution case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 200\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 20\n",
    "dataset_name = 'artificial_sine_two_distribution'\n",
    "validation_dataset_name = 'artificial_sine_two_distribution_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "for j in range(2):\n",
    "    a = 0.1 + rng.random() * (2.0 - 0.1)\n",
    "    b = rng.random() * 2 * np.pi\n",
    "    for i in range(int(number_of_tasks / 2)):\n",
    "        a_array.append(a)\n",
    "        b_array.append(b)\n",
    "        \n",
    "        x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "        x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "        y_train = a * np.sin(x_train + b)\n",
    "        y_val = a * np.sin(x_val + b)\n",
    "        \n",
    "        ind = i + int(number_of_tasks * j / 2)\n",
    "        X_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = x_train.copy()\n",
    "        X_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = x_val.copy()    \n",
    "        y_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = y_train.squeeze(1).copy()\n",
    "        y_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_two_distribution_validated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- alpha = 0.05 --------------------\n",
      "Computing Lipschitz smoothness constant...\n",
      "Current L = 102.400000           744/60000 Iterations: fun_value 0.000330 grad_norm 0.015335 fun_value_on_validation 0.0004574\n",
      "Worker 0 smoothness constant: 0.1\n",
      "Computing Lipschitz smoothness constant...\n",
      "Current L = 0.100000            4032/60000 Iterations: fun_value 0.000068 grad_norm 0.000827 fun_value_on_validation 0.0122901778\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-059c2be5934f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------- alpha = {} --------------------'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMasterNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running GD...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/workers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_workers, alpha, worker, dataset_name, logreg, ordered, max_it, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_validation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothness\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, id_node, alpha, x_train, y_train, tolerance, validation, x_validation, y_validation, gpu, stepsize)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, id_node, alpha, x_train, y_train, regularization, nn_flag, **args)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         print('Worker id: ' + str(self.id))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smoothness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#         print('L smoothness is: ', self.smoothness)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36m_smoothness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_smoothness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smoothness_non_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36m_smoothness_non_gpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current L = {:f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mf_value_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurr_fun_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf_value_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36mfun_value\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36mf_value\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fed_mixture_code/models.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                     \u001b[0mind\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '50_200_two_distribution_validation'\n",
    "for i in range(1, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '/50_200_two_distribution_validation', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=1, ls='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_200_two_distribution_validation.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 8. Two distribution case, 200-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 300\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 20\n",
    "dataset_name = 'artificial_sine_two_distribution_200vs100'\n",
    "validation_dataset_name = 'artificial_sine_two_distribution_validation_200vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "a_array_old = np.load(DATASET_PATH + 'a_two_distribution_validated.npy')\n",
    "b_array_old = np.load(DATASET_PATH + 'b_two_distribution_validated.npy')\n",
    "dist_sizes = [200, 100]\n",
    "for j in range(2):\n",
    "    a = a_array_old[100 * j]\n",
    "    b = b_array_old[100 * j]\n",
    "    for i in range(dist_sizes[j]):\n",
    "        a_array.append(a)\n",
    "        b_array.append(b)\n",
    "        \n",
    "        x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "        x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "        y_train = a * np.sin(x_train + b)\n",
    "        y_val = a * np.sin(x_val + b)\n",
    "        \n",
    "        ind = i + dist_sizes[0] * j\n",
    "        X_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = x_train.copy()\n",
    "        X_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = x_val.copy()    \n",
    "        y_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = y_train.squeeze(1).copy()\n",
    "        y_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_two_distribution_validated_200vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '50_300_two_distribution_validation200vs100'\n",
    "for i in range(1, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '/50_300_two_distribution_validation200vs100', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=1, ls='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_300_two_distribution_validation200vs100.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 9. Two distribution case, 500-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 600\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 20\n",
    "dataset_name = 'artificial_sine_two_distribution_500vs100'\n",
    "validation_dataset_name = 'artificial_sine_two_distribution_validation_500vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "a_array_old = np.load(DATASET_PATH + 'a_two_distribution_validated.npy')\n",
    "b_array_old = np.load(DATASET_PATH + 'b_two_distribution_validated.npy')\n",
    "dist_sizes = [500, 100]\n",
    "for j in range(2):\n",
    "    a = a_array_old[100 * j]\n",
    "    b = b_array_old[100 * j]\n",
    "    for i in range(dist_sizes[j]):\n",
    "        a_array.append(a)\n",
    "        b_array.append(b)\n",
    "        \n",
    "        x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "        x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "        y_train = a * np.sin(x_train + b)\n",
    "        y_val = a * np.sin(x_val + b)\n",
    "        \n",
    "        ind = i + dist_sizes[0] * j\n",
    "        X_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = x_train.copy()\n",
    "        X_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = x_val.copy()    \n",
    "        y_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = y_train.squeeze(1).copy()\n",
    "        y_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_two_distribution_validated_500vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '50_600_two_distribution_validation500vs100'\n",
    "for i in range(1, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '50_600_two_distribution_validation500vs100', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=1, ls='--')\n",
    "plt.title('500 - 100')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_600_two_distribution_validation500vs100.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 10. Two distribution case, 300-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 400\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 20\n",
    "dataset_name = 'artificial_sine_two_distribution_300vs100'\n",
    "validation_dataset_name = 'artificial_sine_two_distribution_validation_300vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "a_array_old = np.load(DATASET_PATH + 'a_two_distribution_validated.npy')\n",
    "b_array_old = np.load(DATASET_PATH + 'b_two_distribution_validated.npy')\n",
    "dist_sizes = [300, 100]\n",
    "for j in range(2):\n",
    "    a = a_array_old[100 * j]\n",
    "    b = b_array_old[100 * j]\n",
    "    for i in range(dist_sizes[j]):\n",
    "        a_array.append(a)\n",
    "        b_array.append(b)\n",
    "        \n",
    "        x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "        x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "        y_train = a * np.sin(x_train + b)\n",
    "        y_val = a * np.sin(x_val + b)\n",
    "        \n",
    "        ind = i + dist_sizes[0] * j\n",
    "        X_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = x_train.copy()\n",
    "        X_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = x_val.copy()    \n",
    "        y_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = y_train.squeeze(1).copy()\n",
    "        y_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_two_distribution_validated_300vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '50_400_two_distribution_validation300vs100'\n",
    "for i in range(5, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "            \n",
    "            if f_value_ is None:\n",
    "                raise Exception('None is detected') \n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '50_400_two_distribution_validation300vs100', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=1, ls='--')\n",
    "plt.title('300 - 100')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_400_two_distribution_validation400vs100.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 11. Two distribution case, 1000-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tasks = 1100\n",
    "number_of_points_per_task = 50\n",
    "number_of_points_per_task_for_validation = 20\n",
    "dataset_name = 'artificial_sine_two_distribution_1000vs100'\n",
    "validation_dataset_name = 'artificial_sine_two_distribution_validation_1000vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task, 1))\n",
    "y_sine = np.empty(shape=(number_of_tasks * number_of_points_per_task))\n",
    "X_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation, 1))\n",
    "y_sine_val = np.empty(shape=(number_of_tasks * number_of_points_per_task_for_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "a_array = []\n",
    "b_array = []\n",
    "a_array_old = np.load(DATASET_PATH + 'a_two_distribution_validated.npy')\n",
    "b_array_old = np.load(DATASET_PATH + 'b_two_distribution_validated.npy')\n",
    "dist_sizes = [1000, 100]\n",
    "for j in range(2):\n",
    "    a = a_array_old[100 * j]\n",
    "    b = b_array_old[100 * j]\n",
    "    for i in range(dist_sizes[j]):\n",
    "        a_array.append(a)\n",
    "        b_array.append(b)\n",
    "        \n",
    "        x_train = -5.0 + rng.random((number_of_points_per_task, 1)) * 10.0\n",
    "        x_val = -5.0 + rng.random((number_of_points_per_task_for_validation, 1)) * 10.0\n",
    "        y_train = a * np.sin(x_train + b)\n",
    "        y_val = a * np.sin(x_val + b)\n",
    "        \n",
    "        ind = i + dist_sizes[0] * j\n",
    "        X_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = x_train.copy()\n",
    "        X_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = x_val.copy()    \n",
    "        y_sine[number_of_points_per_task * ind : number_of_points_per_task * (ind + 1)] = y_train.squeeze(1).copy()\n",
    "        y_sine_val[number_of_points_per_task_for_validation * ind : number_of_points_per_task_for_validation * (ind + 1)] = y_val.squeeze(1).copy()    \n",
    "a_array = np.array(a_array)\n",
    "b_array = np.array(b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1099\n",
    "ind_range = list(range(ind * number_of_points_per_task, (ind + 1) * number_of_points_per_task))\n",
    "plt.scatter(X_sine[ind_range], y_sine[ind_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_sine, y_sine, DATASET_PATH + dataset_name)\n",
    "dump_svmlight_file(X_sine_val, y_sine_val, DATASET_PATH + validation_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = '_two_distribution_validated_1000vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATASET_PATH + 'a' + key_word + '.npy', a_array)\n",
    "np.save(DATASET_PATH + 'b' + key_word + '.npy', b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.load(DATASET_PATH + 'a' + key_word + '.npy')\n",
    "b_array = np.load(DATASET_PATH + 'b' + key_word + '.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n_workers = number_of_tasks\n",
    "exp = 'gd'\n",
    "max_it = 100\n",
    "\n",
    "alg = NN_1d_regression\n",
    "logreg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- alpha = {} --------------------'.format(alpha))\n",
    "model = MasterNode(n_workers, alpha, alg, dataset_name, logreg, True, max_it, tolerance=1e-2, validation=True, validation_dataset_name=validation_dataset_name)\n",
    "print('Running GD...')\n",
    "model.run_gd(max_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(11):\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    models[i].change_alpha(alphas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].change_alpha(0.0)\n",
    "models[0].w_opt_global = np.zeros(models[0].d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(models, filename='a_constant_1000'):\n",
    "    models_dict = {'models' : models}\n",
    "    with open(MODELS_PATH + filename, 'wb') as file:\n",
    "        pickle.dump(models_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saves_name = '50_11000_two_distribution_validation1000vs100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(models, saves_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    model = models[i]\n",
    "    min_L = 0.1\n",
    "    max_L = 0.1\n",
    "    max_it = 10000\n",
    "    tol = 1e-2\n",
    "    max_L_constant = 2 ** 40\n",
    "    w = copy.deepcopy(models[i-1].w_opt_global)\n",
    "    grad_norm = None\n",
    "    min_f_value = float('Inf')\n",
    "\n",
    "    try:\n",
    "        for it in range(max_it):\n",
    "            grad = model.grad(w)\n",
    "            L = min_L\n",
    "            curr_fun_value = model.fun_value(w)\n",
    "\n",
    "            while True:\n",
    "                if L > max_L_constant: # if L becomes too large, jump to another random point w\n",
    "                    w = np.random.randn(model.d)\n",
    "                    grad = model.grad(w)\n",
    "                    L = min_L\n",
    "                    curr_fun_value = model.fun_value(w)\n",
    "\n",
    "                print('Current L = {:f}'.format(L), end='\\r')\n",
    "\n",
    "                f_value_ = model.fun_value(w - grad / L)\n",
    "                if curr_fun_value - f_value_ > 0:\n",
    "                    break\n",
    "                L *= 2.0\n",
    "\n",
    "            w -= grad / L\n",
    "            grad_norm = la.norm(grad)\n",
    "            \n",
    "            if f_value_ is None:\n",
    "                raise Exception('None is detected') \n",
    "\n",
    "            if f_value_ < min_f_value:\n",
    "                min_f_value = f_value_\n",
    "                model.w_opt_global = copy.deepcopy(w)\n",
    "\n",
    "            if max_L < L:\n",
    "                max_L = L\n",
    "            print('                               {:5d}/{:5d} Iterations: fun_value {:f} grad_norm {:f}'.format(it+1, max_it, f_value_, grad_norm), end='\\r')                \n",
    "            if grad_norm < tol and f_value_ < tol ** 2:\n",
    "                save(models, saves_name)\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(min_f_value)\n",
    "    else:\n",
    "        save(models, saves_name)\n",
    "        print('')\n",
    "        print('Unknown problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODELS_PATH + '50_11000_two_distribution_validation1000vs100', 'rb') as file:\n",
    "    models = pickle.load(file)['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    model = models[i]\n",
    "    print(model.fun_value(model.w_opt_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_table = np.empty(shape=(11, models[0].n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 2000\n",
    "rng = default_rng()\n",
    "for i in range(models[0].n_workers):\n",
    "    x_test = -5.0 + rng.random((n_test, 1)) * 10\n",
    "    y_test = a_array[i] * np.sin(x_test + b_array[i])\n",
    "    for j in range(11):\n",
    "        worker = models[j].workers[i]\n",
    "        worker.set_weights(worker.compute_local(models[j].w_opt_global))\n",
    "        y_pred = worker.model(torch.from_numpy(x_test).float()).detach().numpy()\n",
    "        mse = np.mean((y_pred - y_test) ** 2).item()\n",
    "        mse_table[j][i] = copy.copy(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha = np.mean(mse_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0, 1.0, 11)\n",
    "argmin = np.argmin(mse_alpha)\n",
    "alpha_min = alphas[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_alpha[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mse_alpha, marker='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Average MSE over clients')\n",
    "plt.xticks(alphas)\n",
    "plt.axvline(x=alpha_min, ymin = 0, ymax=1, ls='--')\n",
    "plt.title('300 - 100')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_PATH + '/50_1100_two_distribution_validation1000vs100.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
